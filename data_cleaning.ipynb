{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotions Episodes Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_id</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9279985</td>\n",
       "      <td>33</td>\n",
       "      <td>22659137</td>\n",
       "      <td>2023-09-04 12:31:12 +0000 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8355786</td>\n",
       "      <td>34</td>\n",
       "      <td>22659137</td>\n",
       "      <td>2023-01-28 21:45:44 +0000 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8987962</td>\n",
       "      <td>31</td>\n",
       "      <td>22659137</td>\n",
       "      <td>2023-05-10 19:18:18 +0000 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9333705</td>\n",
       "      <td>30</td>\n",
       "      <td>22659137</td>\n",
       "      <td>2022-10-08 12:51:28 +0000 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9138258</td>\n",
       "      <td>30</td>\n",
       "      <td>22659137</td>\n",
       "      <td>2022-11-17 11:56:07 +0000 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_id  emotion_id   user_id                        created\n",
       "0     9279985          33  22659137  2023-09-04 12:31:12 +0000 UTC\n",
       "1     8355786          34  22659137  2023-01-28 21:45:44 +0000 UTC\n",
       "2     8987962          31  22659137  2023-05-10 19:18:18 +0000 UTC\n",
       "3     9333705          30  22659137  2022-10-08 12:51:28 +0000 UTC\n",
       "4     9138258          30  22659137  2022-11-17 11:56:07 +0000 UTC"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './raw_data/emotions_episode_votes.csv'\n",
    "file_path_new = './data/emotions_episode_votes_modified.csv'\n",
    "\n",
    "# Attempt to correctly parse the CSV file by detecting the delimiter automatically\n",
    "df_new_corrected = pd.read_csv(file_path, sep=None, engine='python')\n",
    "\n",
    "# Convert the column names to lowercase\n",
    "df_new_corrected.columns = map(str.lower, df_new_corrected.columns)\n",
    "\n",
    "# Retain only the specified columns\n",
    "columns_to_keep_corrected = ['episode_id', 'emotion_id', 'user_id', 'created']\n",
    "df_new_filtered = df_new_corrected[columns_to_keep_corrected]\n",
    "\n",
    "# Display the modified dataframe\n",
    "df_new_filtered.head()\n",
    "\n",
    "# # Save the modified dataframe to a new CSV file\n",
    "# df_new_filtered.to_csv(file_path_new, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episode Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './raw_data/episode_comment.csv'\n",
    "file_path_new = './data/episode_comment_modified.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "# Filter the rows where depth is greater than 0 - we don't want the replies to the comments\n",
    "df_filtered = df[df['depth'] < 1]\n",
    "\n",
    "# Select only specified columns\n",
    "df_filtered = df_filtered[['episode_id', 'tv_show_name', 'episode_season_number', 'episode_number', 'user_id', 'comment', 'nb_likes', 'created_at', 'updated_at']]\n",
    "\n",
    "df_filtered.head()\n",
    "\n",
    "# Save the modified dataframe to a new CSV file\n",
    "df_filtered.to_csv(file_path_new, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Followed TV Show preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './raw_data/followed_tv_show.csv'\n",
    "file_path_new = './data/followed_tv_show_modified.csv'\n",
    "\n",
    "# Attempt to correctly parse the CSV file by detecting the delimiter automatically\n",
    "df_new_corrected = pd.read_csv(file_path, sep=None, engine='python')\n",
    "\n",
    "# Display the corrected dataframe structure to verify the column names and data\n",
    "df_new_corrected.head()\n",
    "\n",
    "# Retain only the specified columns\n",
    "columns_to_keep_corrected = ['tv_show_name', 'tv_show_id', 'created_at', 'active', 'archived', 'user_id']\n",
    "df_new_filtered = df_new_corrected[columns_to_keep_corrected]\n",
    "\n",
    "# Display the modified dataframe\n",
    "df_new_filtered.head()\n",
    "\n",
    "# Save the modified dataframe to a new CSV file\n",
    "df_new_filtered.to_csv(file_path_new, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating Episode preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a mapping from order values to note values\n",
    "order_mapping = {'1': 1, '27': 2, '28': 3, '29': 4, '3': 5}\n",
    "\n",
    "# Function to convert order and RATING_ID to note\n",
    "def convert_to_note(row):\n",
    "    # Split the 'order' string into a list of strings, then convert to a list of integers\n",
    "    order_values = list(map(int, row['order'].split(',')))\n",
    "    # Get the index of RATING_ID in order_values, then use this index to find the corresponding note value\n",
    "    try:\n",
    "        rating_index = order_values.index(row['RATING_ID'])\n",
    "        return order_mapping[str(order_values[rating_index])]\n",
    "    except ValueError:\n",
    "        # In case the RATING_ID is not found in the order list, return NaN or some error indicator\n",
    "        return float('nan')\n",
    "\n",
    "file_path = './raw_data/ratings_episode_votes.csv'\n",
    "df = pd.read_csv(file_path, sep=None, engine='python')\n",
    "\n",
    "# Apply the conversion function to each row\n",
    "df['note'] = df.apply(convert_to_note, axis=1)\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['order', 'RATING_ID', 'VOTE_KEY', 'IS_DELETED', 'DB_UPDATE_TS', 'set']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# Display the modified dataframe\n",
    "df.head()\n",
    "\n",
    "\n",
    "# Save the modified dataframe to a new CSV file\n",
    "output_file_path = './data/ratings_episode_votes_modified.csv'\n",
    "df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seen Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_5900\\2801304209.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "rewatched_episode_df = pd.read_csv('./raw_data/rewatched_episode.csv')\n",
    "seen_episode_df = pd.read_csv('./raw_data/seen_episode.csv')\n",
    "\n",
    "# Drop updated_at of seen_episode_df\n",
    "seen_episode_df.drop(columns=['updated_at', 'tweet_id'], inplace=True)\n",
    "# Drop created_at of rewatched_episode_df\n",
    "rewatched_episode_df.drop(columns=['created_at'], inplace=True)\n",
    "\n",
    "# Merge the datasets on specified columns\n",
    "merge_columns = ['tv_show_name', 'episode_season_number', 'episode_number', 'user_id', 'episode_id']\n",
    "final_df = pd.merge(seen_episode_df, rewatched_episode_df[merge_columns + ['cpt']], \n",
    "                    on=merge_columns, \n",
    "                    how='left')\n",
    "\n",
    "# Replace NaN in rewatched_count with 0\n",
    "final_df['rewatched_count'] = final_df['cpt'].fillna(0).astype(int)\n",
    "final_df.drop(columns=['cpt'], inplace=True)  # Drop the 'cpt' column as it's no longer needed\n",
    "\n",
    "# Remove the rows where tv_show_name is NaN or empty\n",
    "final_df = final_df[final_df['tv_show_name'].notna()]\n",
    "\n",
    "# # Select and rename relevant columns for the final dataset\n",
    "# final_dataset = final_df[['updated_at', 'tv_show_name', 'episode_season_number', 'episode_number', \n",
    "#                           'user_id', 'episode_id', 'created_at', 'rewatched_count']]\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "final_df.head()\n",
    "\n",
    "# Save the final dataset to a new CSV file\n",
    "file_path_new = './data/seen_episode_modified.csv'\n",
    "final_df.to_csv(file_path_new, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
